{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tesla07/Adele-lyrics_classifier_n_generator/blob/main/adele's_song_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4Rf08EhdXwxX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ytG86j2ZX2PC",
        "outputId": "f852caa3-bbb4-473b-cd31-03bed813dd95"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-db04433b-97c3-4ddf-960a-4d5bc077b306\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-db04433b-97c3-4ddf-960a-4d5bc077b306\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Adele.csv to Adele (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Adele.csv'\n",
        "spotify_data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "p_DTpr_NX4Hx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "# Clean the lyrics data\n",
        "spotify_data['clean_lyrics'] = spotify_data['text'].str.replace('[^a-zA-Z\\s]', '', regex=True).str.lower()\n",
        "\n",
        "\n",
        "# Tokenize the lyrics using numpy\n",
        "spotify_data['tokenized_lyrics'] = spotify_data['clean_lyrics'].apply(lambda x: np.array(x.split()))\n",
        "\n",
        "# Remove stop words (assuming 'stop_words' a list of stop words)\n",
        "stop_words = ['a', 'an', 'the', 'is', 'of', 'and', 'it']  # Define the stop words\n",
        "spotify_data['filtered_lyrics'] = spotify_data['tokenized_lyrics'].apply(lambda x: np.array([word for word in x if word not in stop_words]))"
      ],
      "metadata": {
        "id": "9iWs55irY3X2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis using a custom approach\n",
        "# Define your own sentiment scoring system using numpy\n",
        "# This could involve counting positive and negative words, or using other custom rules\n",
        "\n",
        "# For example, defining a simple sentiment score based on the presence of certain words\n",
        "# Positive Words# Positive Words\n",
        "positive_words = ['love', 'joy', 'happy', 'sun', 'dream', 'free', 'happiness', 'dream', 'hope', 'laugh']\n",
        "\n",
        "# Negative Words\n",
        "negative_words = ['heartbreak', 'pain', 'tears', 'sad', 'lonely', 'dark', 'angry', 'hate', 'death', 'die','last', 'never', 'cruel', 'forgiveness', 'worse']\n",
        "\n",
        "# Function to calculate sentiment score\n",
        "def calculate_sentiment_score(words):\n",
        "    positive_score = np.sum([word in positive_words for word in words])\n",
        "    negative_score = np.sum([word in negative_words for word in words])\n",
        "    total_score = positive_score - negative_score\n",
        "    return total_score\n",
        "\n",
        "# Apply sentiment scoring\n",
        "spotify_data['sentiment_score'] = spotify_data['filtered_lyrics'].apply(lambda x: calculate_sentiment_score(x))\n",
        "\n",
        "# Map sentiment scores to mood categories\n",
        "def classify_mood(score):\n",
        "    if score > 0:\n",
        "        return 'Happy'\n",
        "    elif score < 0:\n",
        "        return 'Sad'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "spotify_data['mood_category'] = spotify_data['sentiment_score'].apply(classify_mood)\n",
        "print(spotify_data[['song', 'mood_category']])\n",
        "\n",
        "# Now you can move on to deploying your model and using it to predict the mood of songs based on their lyrics."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSMkhcXKY7g1",
        "outputId": "e19d5f64-eba9-49e2-87e2-41fa1a3338fb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                song mood_category\n",
            "0                          All I Ask           Sad\n",
            "1                       Can't Let Go           Sad\n",
            "2                      Crazy For You           Sad\n",
            "3                         Daydreamer       Neutral\n",
            "4                              Hello           Sad\n",
            "5                         I Miss You           Sad\n",
            "6             Melt My Heart To Stone         Happy\n",
            "7                      Need You Know       Neutral\n",
            "8                       Now And Then         Happy\n",
            "9                   Someone Like You       Neutral\n",
            "10   Think That I Get Told The Court         Happy\n",
            "11         You'll Never See Me Again           Sad\n",
            "12                     Best For Last           Sad\n",
            "13                    Black And Gold           Sad\n",
            "14                 Chasing Pavements         Happy\n",
            "15                     Cold Shoulder           Sad\n",
            "16                Don't You Remember         Happy\n",
            "17                            Fiasco         Happy\n",
            "18                        First Love         Happy\n",
            "19                   For An Eternity         Happy\n",
            "20                       He Won't Go         Happy\n",
            "21                   Hiding My Heart         Happy\n",
            "22                    Hometown Glory         Happy\n",
            "23             I Dare You To Love Me           Sad\n",
            "24                     I Found A Boy         Happy\n",
            "25        If it Hadn't Been for Love         Happy\n",
            "26                   I'll Be Waiting         Happy\n",
            "27                         Last Nite           Sad\n",
            "28                       Lay Me Down       Neutral\n",
            "29                  Love In The Dark           Sad\n",
            "30                          Lovesong         Happy\n",
            "31             Make You Feel My Love         Happy\n",
            "32              Many Shades Of Black       Neutral\n",
            "33                 Million Years Ago           Sad\n",
            "34                           My Same           Sad\n",
            "35             Never Gonna Leave You           Sad\n",
            "36               Never Tear Us Apart           Sad\n",
            "37                  Not Drunk Enough         Happy\n",
            "38                      One And Only           Sad\n",
            "39                            Remedy       Neutral\n",
            "40                     Right As Rain         Happy\n",
            "41                         River Lea           Sad\n",
            "42               Rolling In The Deep           Sad\n",
            "43                     Rumour Has It         Happy\n",
            "44                   Send My Love To         Happy\n",
            "45  Send My Love (To Your New Lover)         Happy\n",
            "46              Set Fire To The Rain           Sad\n",
            "47                Steady As She Goes       Neutral\n",
            "48                       Take It All         Happy\n",
            "49    That's It I Quit I'm Movin' On         Happy\n",
            "50                             Tired           Sad\n",
            "51                    Turning Tables       Neutral\n",
            "52            Water Under The Bridge         Happy\n",
            "53                When We Were Young           Sad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first few rows of the dataset\n",
        "print(spotify_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avR9pck1b2rE",
        "outputId": "cee5d48c-3c1d-4c91-8dc6-66b450df9cac"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  artist           song                                  link  \\\n",
            "0  Adele      All I Ask      /a/adele/all+i+ask_21105101.html   \n",
            "1  Adele   Can't Let Go    /a/adele/cant+let+go_21105103.html   \n",
            "2  Adele  Crazy For You  /a/adele/crazy+for+you_20830095.html   \n",
            "3  Adele     Daydreamer     /a/adele/daydreamer_20730061.html   \n",
            "4  Adele          Hello          /a/adele/hello_21103519.html   \n",
            "\n",
            "                                                text  \\\n",
            "0  [Verse 1]  \\nI will leave my heart at the door...   \n",
            "1  [Verse 1]  \\nWhen did it go wrong, I will neve...   \n",
            "2  Found myself today singing out your name,  \\nY...   \n",
            "3  Daydreamer  \\nSitting on the sea  \\nSoaking up...   \n",
            "4  [Verse 1]  \\nHello, it's me  \\nI was wondering...   \n",
            "\n",
            "                                        clean_lyrics  \\\n",
            "0  verse   \\ni will leave my heart at the door  \\...   \n",
            "1  verse   \\nwhen did it go wrong i will never kn...   \n",
            "2  found myself today singing out your name  \\nyo...   \n",
            "3  daydreamer  \\nsitting on the sea  \\nsoaking up...   \n",
            "4  verse   \\nhello its me  \\ni was wondering if a...   \n",
            "\n",
            "                                    tokenized_lyrics  \\\n",
            "0  [verse, i, will, leave, my, heart, at, the, do...   \n",
            "1  [verse, when, did, it, go, wrong, i, will, nev...   \n",
            "2  [found, myself, today, singing, out, your, nam...   \n",
            "3  [daydreamer, sitting, on, the, sea, soaking, u...   \n",
            "4  [verse, hello, its, me, i, was, wondering, if,...   \n",
            "\n",
            "                                     filtered_lyrics  sentiment_score  \\\n",
            "0  [verse, i, will, leave, my, heart, at, door, i...               -4   \n",
            "1  [verse, when, did, go, wrong, i, will, never, ...               -7   \n",
            "2  [found, myself, today, singing, out, your, nam...               -1   \n",
            "3  [daydreamer, sitting, on, sea, soaking, up, su...                0   \n",
            "4  [verse, hello, its, me, i, was, wondering, if,...               -1   \n",
            "\n",
            "  mood_category  \n",
            "0           Sad  \n",
            "1           Sad  \n",
            "2           Sad  \n",
            "3       Neutral  \n",
            "4           Sad  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target variable (y)\n",
        "X = spotify_data['filtered_lyrics']\n",
        "y = spotify_data['mood_category']"
      ],
      "metadata": {
        "id": "FTgzgyujd2E2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets without sklearn\n",
        "mask = np.random.rand(len(spotify_data)) < 0.8\n",
        "train_data = spotify_data[mask]\n",
        "test_data = spotify_data[~mask]"
      ],
      "metadata": {
        "id": "pnmFqLg2fCio"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target variable (y)\n",
        "X_train = train_data['filtered_lyrics']\n",
        "y_train = train_data['mood_category']\n",
        "X_test = test_data['filtered_lyrics']\n",
        "y_test = test_data['mood_category']"
      ],
      "metadata": {
        "id": "W4k8nU5gfE2n"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = np.unique(np.hstack(X_train.apply(lambda x: np.unique(x)).values))\n",
        "\n",
        "# Create a dictionary mapping each unique word to its index\n",
        "word_to_index = {word: idx for idx, word in enumerate(unique_words)}\n"
      ],
      "metadata": {
        "id": "Sr8A_ax1fICa"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, word_to_index):\n",
        "    vector = np.zeros(len(word_to_index))\n",
        "    for word in text:\n",
        "        if word in word_to_index:\n",
        "            vector[word_to_index[word]] += 1\n",
        "    return vector\n",
        "\n",
        "X_train_vectorized = np.array([vectorize_text(text, word_to_index) for text in X_train])\n",
        "X_test_vectorized = np.array([vectorize_text(text, word_to_index) for text in X_test])"
      ],
      "metadata": {
        "id": "ZGxfqeNql9XD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultinomialNB:\n",
        "    def __init__(self):\n",
        "        self.class_probs = {}\n",
        "        self.word_probs = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "        total_samples = len(y)\n",
        "\n",
        "        for cls, count in zip(unique_classes, class_counts):\n",
        "            self.class_probs[cls] = count / total_samples\n",
        "\n",
        "        for cls in unique_classes:\n",
        "            cls_indices = np.where(y == cls)\n",
        "            cls_texts = X[cls_indices]\n",
        "            total_words_in_cls = np.sum(cls_texts)\n",
        "            self.word_probs[cls] = np.sum(cls_texts, axis=0) / total_words_in_cls\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "\n",
        "        for text in X:\n",
        "            scores = {}\n",
        "\n",
        "            for cls in self.class_probs:\n",
        "                score = np.log(self.class_probs[cls])\n",
        "                score += np.sum(np.log(self.word_probs[cls] + 1) * text)\n",
        "                scores[cls] = score\n",
        "\n",
        "            predicted_class = max(scores, key=scores.get)\n",
        "            predictions.append(predicted_class)\n",
        "\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "id": "gdkQVHDCfV1t"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit the classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_vectorized, y_train)"
      ],
      "metadata": {
        "id": "D2waUcetrok9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test_vectorized)\n"
      ],
      "metadata": {
        "id": "QDNM1DdFrqIB"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    correct = np.sum(y_true == y_pred)\n",
        "    total = len(y_true)\n",
        "    return correct / total\n",
        "\n",
        "def precision_recall_f1(y_true, y_pred):\n",
        "    unique_classes = np.unique(np.concatenate([y_true, y_pred]))\n",
        "    metrics = {}\n",
        "\n",
        "    for cls in unique_classes:\n",
        "        true_positive = np.sum((y_true == cls) & (y_pred == cls))\n",
        "        false_positive = np.sum((y_true != cls) & (y_pred == cls))\n",
        "        false_negative = np.sum((y_true == cls) & (y_pred != cls))\n",
        "\n",
        "        precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
        "        recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        metrics[cls] = {'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
        "\n",
        "    return metrics\n",
        "\n",
        "print(\"Accuracy:\", accuracy(y_test.values, y_pred))\n",
        "print(\"Classification Report:\\n\", precision_recall_f1(y_test.values, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV5jbQj-rtXn",
        "outputId": "c2859508-cb14-46e6-f99f-bc910d20965d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.16666666666666666\n",
            "Classification Report:\n",
            " {'Happy': {'Precision': 0.18181818181818182, 'Recall': 1.0, 'F1 Score': 0.3076923076923077}, 'Neutral': {'Precision': 0, 'Recall': 0.0, 'F1 Score': 0}, 'Sad': {'Precision': 0.0, 'Recall': 0.0, 'F1 Score': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define a function to generate lyrics based on mood\n",
        "def generate_lyrics_randomly(vocabulary, num_words=50):\n",
        "    # Randomly sample words from the vocabulary to generate lyrics\n",
        "    generated_lyrics = ' '.join(random.sample(vocabulary, min(num_words, len(vocabulary))))\n",
        "\n",
        "    return generated_lyrics\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have the vocabulary from the dataset\n",
        "vocabulary = set(word for lyrics in spotify_data['filtered_lyrics'] for word in lyrics)\n",
        "\n",
        "mood_to_generate = 'neutral'\n",
        "generated_lyrics = generate_lyrics_randomly(vocabulary)\n",
        "print(f\"Generated Lyrics for {mood_to_generate} mood:\\n\", generated_lyrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSpDEk8YugA1",
        "outputId": "c17ec5a1-3255-446b-d9ea-08d3aee56e57"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Lyrics for neutral mood:\n",
            " tingle learning choke mouth stranger couldve scars desert iiiii were youll obviously haunted raging lover hollywood yesterday giving city straight favorite gonna caused take in hustle trouble anything become other chorus used posses stay already born threw excusing write guess uninvited lipstick quiet chasing me lump changed clearly married difference\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-d43b1d951704>:6: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  generated_lyrics = ' '.join(random.sample(vocabulary, min(num_words, len(vocabulary))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oalw_58e7nMv"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9urFIWIFfhYH"
      },
      "execution_count": 54,
      "outputs": []
    }
  ]
}